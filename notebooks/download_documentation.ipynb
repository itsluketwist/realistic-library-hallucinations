{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d384ca",
   "metadata": {},
   "source": [
    "# Download all the library members from documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c60ed3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need documentation for 30 libraries:\n",
      "\t['bs4', 'chardet', 'cryptography', 'dateutil', 'django', 'folium', 'librosa', 'lxml', 'matplotlib', 'nltk', 'numpy', 'openpyxl', 'pandas', 'psutil', 'pytesseract', 'pytz', 'regex', 'requests', 'scipy', 'seaborn', 'sklearn', 'statsmodels', 'sympy', 'tensorflow', 'textblob', 'texttable', 'wordcloud', 'wordninja', 'xlwt', 'xmltodict']\n"
     ]
    }
   ],
   "source": [
    "# get list of libraries we need for the study\n",
    "\n",
    "from src.constants import DOCUMENTED_LIBRARIES\n",
    "\n",
    "print(\n",
    "    f\"Need documentation for {len(DOCUMENTED_LIBRARIES)} libraries:\\n\\t{DOCUMENTED_LIBRARIES}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00efa1ae",
   "metadata": {},
   "source": [
    "## **1.** Manually download 6 smaller libraries without parsable documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "893e8ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 6 manually scraped libraries.\n"
     ]
    }
   ],
   "source": [
    "# small libraries, scraped manually from the source code\n",
    "\n",
    "manually_scraped = {\n",
    "    \"wordninja\": {\n",
    "        \"url\": \"https://github.com/keredson/wordninja/blob/master/wordninja.py\",\n",
    "        \"version\": \"2.0.0\",\n",
    "        \"modules\": [\n",
    "            \"wordninja\",\n",
    "        ],\n",
    "        \"members\": [\n",
    "            \"wordninja\",\n",
    "            \"wordninja.LanguageModel\",\n",
    "            \"wordninja.DEFAULT_LANGUAGE_MODEL\",\n",
    "            \"wordninja.split\",\n",
    "        ],\n",
    "    },\n",
    "    \"texttable\": {\n",
    "        \"url\": \"https://github.com/foutaise/texttable/blob/master/texttable.py\",\n",
    "        \"version\": \"1.7.0\",\n",
    "        \"modules\": [\n",
    "            \"texttable\",\n",
    "        ],\n",
    "        \"members\": [\n",
    "            \"texttable\",\n",
    "            \"texttable.Texttable\",\n",
    "            \"texttable.ArraySizeError\",\n",
    "            \"texttable.obj2unicode\",\n",
    "            \"texttable.len\",\n",
    "        ],\n",
    "    },\n",
    "    \"xmltodict\": {\n",
    "        \"url\": \"https://github.com/martinblech/xmltodict/blob/master/xmltodict.py\",\n",
    "        \"version\": \"0.14.2\",\n",
    "        \"modules\": [\n",
    "            \"xmltodict\",\n",
    "        ],\n",
    "        \"members\": [\n",
    "            \"xmltodict\",\n",
    "            \"xmltodict.parse\",\n",
    "            \"xmltodict.unparse\",\n",
    "            \"xmltodict.ParsingInterrupted\",\n",
    "        ],\n",
    "    },\n",
    "    \"regex\": {\n",
    "        \"url\": \"https://github.com/mrabarnett/mrab-regex/blob/hg/regex_3/regex.py\",\n",
    "        \"version\": \"2.5.153\",\n",
    "        \"modules\": [\n",
    "            \"regex\",\n",
    "        ],\n",
    "        \"members\": [\n",
    "            \"regex\",\n",
    "            \"regex.cache_all\",\n",
    "            \"regex.compile\",\n",
    "            \"regex.DEFAULT_VERSION\",\n",
    "            \"regex.escape\",\n",
    "            \"regex.findall\",\n",
    "            \"regex.finditer\",\n",
    "            \"regex.fullmatch\",\n",
    "            \"regex.match\",\n",
    "            \"regex.purge\",\n",
    "            \"regex.search\",\n",
    "            \"regex.split\",\n",
    "            \"regex.splititer\",\n",
    "            \"regex.sub\",\n",
    "            \"regex.subf\",\n",
    "            \"regex.subfn\",\n",
    "            \"regex.subn\",\n",
    "            \"regex.template\",\n",
    "            \"regex.Scanner\",\n",
    "            \"regex.A\",\n",
    "            \"regex.ASCII\",\n",
    "            \"regex.B\",\n",
    "            \"regex.BESTMATCH\",\n",
    "            \"regex.D\",\n",
    "            \"regex.DEBUG\",\n",
    "            \"regex.E\",\n",
    "            \"regex.ENHANCEMATCH\",\n",
    "            \"regex.S\",\n",
    "            \"regex.DOTALL\",\n",
    "            \"regex.F\",\n",
    "            \"regex.FULLCASE\",\n",
    "            \"regex.I\",\n",
    "            \"regex.IGNORECASE\",\n",
    "            \"regex.L\",\n",
    "            \"regex.LOCALE\",\n",
    "            \"regex.M\",\n",
    "            \"regex.MULTILINE\",\n",
    "            \"regex.P\",\n",
    "            \"regex.POSIX\",\n",
    "            \"regex.R\",\n",
    "            \"regex.REVERSE\",\n",
    "            \"regex.T\",\n",
    "            \"regex.TEMPLATE\",\n",
    "            \"regex.U\",\n",
    "            \"regex.UNICODE\",\n",
    "            \"regex.V0\",\n",
    "            \"regex.VERSION0\",\n",
    "            \"regex.V1\",\n",
    "            \"regex.VERSION1\",\n",
    "            \"regex.X\",\n",
    "            \"regex.VERBOSE\",\n",
    "            \"regex.W\",\n",
    "            \"regex.WORD\",\n",
    "            \"regex.error\",\n",
    "            \"regex.Regex\",\n",
    "            \"regex.__version__\",\n",
    "            \"regex.__doc__\",\n",
    "            \"regex.RegexFlag\",\n",
    "        ],\n",
    "    },\n",
    "    \"pytz\": {\n",
    "        \"url\": \"https://github.com/stub42/pytz/blob/master/src/pytz/__init__.py\",\n",
    "        \"version\": \"2025.2\",\n",
    "        \"modules\": [\n",
    "            \"pytz\",\n",
    "        ],\n",
    "        \"members\": [\n",
    "            \"pytz\",\n",
    "            \"pytz.timezone\",\n",
    "            \"pytz.utc\",\n",
    "            \"pytz.country_timezones\",\n",
    "            \"pytz.country_names\",\n",
    "            \"pytz.all_timezones\",\n",
    "            \"pytz.all_timezones_set\",\n",
    "            \"pytz.common_timezones\",\n",
    "            \"pytz.common_timezones_set\",\n",
    "            \"pytz.BaseTzInfo\",\n",
    "            \"pytz.FixedOffset\",\n",
    "            \"pytz.AmbiguousTimeError\",\n",
    "            \"pytz.InvalidTimeError\",\n",
    "            \"pytz.NonExistentTimeError\",\n",
    "            \"pytz.UnknownTimeZoneError\",\n",
    "            \"pytz.exceptions\",\n",
    "            \"pytz.exceptions.AmbiguousTimeError\",\n",
    "            \"pytz.exceptions.InvalidTimeError\",\n",
    "            \"pytz.exceptions.NonExistentTimeError\",\n",
    "            \"pytz.exceptions.UnknownTimeZoneError\",\n",
    "            \"pytz.tzinfo\",\n",
    "            \"pytz.tzinfo.memorized_timedelta\",\n",
    "            \"pytz.tzinfo.memorized_datetime\",\n",
    "            \"pytz.tzinfo.memorized_ttinfo\",\n",
    "            \"pytz.tzinfo.BaseTzInfo\",\n",
    "            \"pytz.tzinfo.StaticTzInfo\",\n",
    "            \"pytz.tzinfo.DstTzInfo\",\n",
    "            \"pytz.tzinfo.unpickler\",\n",
    "            \"pytz.tzfile\",\n",
    "            \"pytz.tzfile.build_tzinfo\",\n",
    "            \"pytz.reference\",\n",
    "            \"pytz.reference.FixedOffset\",\n",
    "            \"pytz.reference.LocalTimezone\",\n",
    "            \"pytz.reference.USTimeZone\",\n",
    "            \"pytz.reference.Eastern\",\n",
    "            \"pytz.reference.Central\",\n",
    "            \"pytz.reference.Mountain\",\n",
    "            \"pytz.reference.Pacific\",\n",
    "            \"pytz.reference.UTC\",\n",
    "            \"pytz.lazy\",\n",
    "            \"pytz.lazy.LazyDict\",\n",
    "            \"pytz.lazy.LazyList\",\n",
    "            \"pytz.lazy.LazySet\",\n",
    "        ],\n",
    "    },\n",
    "    \"pytesseract\": {\n",
    "        \"url\": \"https://github.com/madmaze/pytesseract\",\n",
    "        \"version\": \"0.3.13\",\n",
    "        \"modules\": [\n",
    "            \"pytesseract\",\n",
    "        ],\n",
    "        \"members\": [\n",
    "            \"pytesseract\",\n",
    "            \"pytesseract.DEFAULT_ENCODING\",\n",
    "            \"pytesseract.LANG_PATTERN\",\n",
    "            \"pytesseract.RGB_MODE\",\n",
    "            \"pytesseract.SUPPORTED_FORMATS\",\n",
    "            \"pytesseract.OSD_KEYS\",\n",
    "            \"pytesseract.EXTENTION_TO_CONFIG\",\n",
    "            \"pytesseract.TESSERACT_MIN_VERSION\",\n",
    "            \"pytesseract.TESSERACT_ALTO_VERSION\",\n",
    "            \"pytesseract.Output\",\n",
    "            \"pytesseract.PandasNotSupported\",\n",
    "            \"pytesseract.TesseractError\",\n",
    "            \"pytesseract.TesseractNotFoundError\",\n",
    "            \"pytesseract.TSVNotSupported\",\n",
    "            \"pytesseract.ALTONotSupported\",\n",
    "            \"pytesseract.kill\",\n",
    "            \"pytesseract.timeout_manager\",\n",
    "            \"pytesseract.run_once\",\n",
    "            \"pytesseract.get_errors\",\n",
    "            \"pytesseract.cleanup\",\n",
    "            \"pytesseract.prepare\",\n",
    "            \"pytesseract.save\",\n",
    "            \"pytesseract.subprocess_args\",\n",
    "            \"pytesseract.run_tesseract\",\n",
    "            \"pytesseract.run_and_get_multiple_output\",\n",
    "            \"pytesseract.run_and_get_output\",\n",
    "            \"pytesseract.file_to_dict\",\n",
    "            \"pytesseract.is_valid\",\n",
    "            \"pytesseract.osd_to_dict\",\n",
    "            \"pytesseract.get_languages\",\n",
    "            \"pytesseract.get_tesseract_version\",\n",
    "            \"pytesseract.image_to_string\",\n",
    "            \"pytesseract.image_to_pdf_or_hocr\",\n",
    "            \"pytesseract.image_to_alto_xml\",\n",
    "            \"pytesseract.image_to_boxes\",\n",
    "            \"pytesseract.get_pandas_output\",\n",
    "            \"pytesseract.image_to_data\",\n",
    "            \"pytesseract.image_to_osd\",\n",
    "            \"pytesseract.main\",\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"Have {len(manually_scraped)} manually scraped libraries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6c260e",
   "metadata": {},
   "source": [
    "## **2.** Automatically download the inventory of 21 libraries using Sphinx / readthedocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6aca33b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the inventory urls for libraries with sphinx / readthedocs documentation\n",
    "\n",
    "inventory_urls = {\n",
    "    \"openpyxl\": \"https://openpyxl.readthedocs.io/en/latest/objects.inv\",\n",
    "    \"django\": \"https://docs.djangoproject.com/en/stable/objects.inv\",\n",
    "    \"statsmodels\": \"https://www.statsmodels.org/stable/objects.inv\",\n",
    "    \"wordcloud\": \"https://amueller.github.io/word_cloud/objects.inv\",\n",
    "    \"librosa\": \"https://librosa.org/doc/latest/objects.inv\",\n",
    "    \"psutil\": \"https://psutil.readthedocs.io/en/latest/objects.inv\",\n",
    "    \"chardet\": \"https://chardet.readthedocs.io/en/latest/objects.inv\",\n",
    "    \"textblob\": \"https://textblob.readthedocs.io/en/latest/objects.inv\",\n",
    "    \"xlwt\": \"https://xlwt.readthedocs.io/en/latest/objects.inv\",\n",
    "    \"dateutil\": \"https://dateutil.readthedocs.io/en/stable/objects.inv\",\n",
    "    \"scipy\": \"https://docs.scipy.org/doc/scipy/objects.inv\",\n",
    "    \"seaborn\": \"https://seaborn.pydata.org/objects.inv\",\n",
    "    \"cryptography\": \"https://cryptography.io/en/latest/objects.inv\",\n",
    "    \"pandas\": \"https://pandas.pydata.org/pandas-docs/stable/objects.inv\",\n",
    "    \"numpy\": \"https://numpy.org/doc/stable/objects.inv\",\n",
    "    \"sklearn\": \"https://scikit-learn.org/stable/objects.inv\",\n",
    "    \"matplotlib\": \"https://matplotlib.org/stable/objects.inv\",\n",
    "    \"sympy\": \"https://docs.sympy.org/latest/objects.inv\",\n",
    "    \"requests\": \"https://docs.python-requests.org/en/latest/objects.inv\",\n",
    "    \"bs4\": \"https://www.crummy.com/software/BeautifulSoup/bs4/doc/objects.inv\",\n",
    "    \"folium\": \"https://python-visualization.github.io/folium/latest/objects.inv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a51f14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method to fetch the inventory and extract importable python objects\n",
    "\n",
    "import sphobjinv as soi\n",
    "\n",
    "python_objects = {\n",
    "    \"module\",\n",
    "    \"class\",\n",
    "    \"exception\",\n",
    "    \"function\",\n",
    "    \"data\",\n",
    "    # all of these are parts of classes, and not importable on their own, so ignored\n",
    "    # \"method\", \"attribute\", \"property\",\n",
    "}\n",
    "\n",
    "\n",
    "def get_library_objects(library: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fetch the inventory from the given URL and return a dictionary with library info.\n",
    "    \"\"\"\n",
    "    # download the inventory\n",
    "    print(f\"Scraping {library}...\")\n",
    "    inv = soi.Inventory(url=inventory_urls[library])\n",
    "\n",
    "    # filter to only importable python objects\n",
    "    base_members = set()\n",
    "    for obj in inv.objects:\n",
    "        if obj.domain == \"py\" and obj.role in python_objects:\n",
    "            base_members.add(obj.name)\n",
    "\n",
    "    # filter the members to catch any excessive inclusions by the sphinx file\n",
    "    final_members = {library}\n",
    "    for member in base_members:\n",
    "        # sometimes other library members are included in the inventory, which we want to ignore\n",
    "        if any(\n",
    "            member.startswith(f\"{_m}.\") for _m in set(DOCUMENTED_LIBRARIES) - {library}\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        # ignore any private members\n",
    "        if any(_section.startswith(\"_\") for _section in member.split(\".\")):\n",
    "            continue\n",
    "\n",
    "        # check if member marked as a module should instead have a parent\n",
    "        if \".\" not in member:\n",
    "            if any((member in m) and m != member for m in base_members):\n",
    "                final_members.add(f\"{library}.{member}\")\n",
    "            else:\n",
    "                final_members.add(member)\n",
    "            continue\n",
    "\n",
    "        # skip any members that are known errors\n",
    "        if any(\n",
    "            member.startswith(f\"{_skip}\") for _skip in [\"asgiref\", \"object\", \"builtins\"]\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        # otherwise add the member as is\n",
    "        final_members.add(member)\n",
    "\n",
    "    print(f\"Have {len(final_members)} members for {library}.\")\n",
    "    return {\n",
    "        \"url\": inventory_urls[library],\n",
    "        \"version\": inv.version,\n",
    "        \"modules\": sorted(set(m.split(\".\")[0] for m in final_members)),\n",
    "        \"members\": sorted(final_members),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80876336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping openpyxl...\n",
      "Have 800 members for openpyxl.\n",
      "Scraping django...\n",
      "Have 1162 members for django.\n",
      "Scraping statsmodels...\n",
      "Have 909 members for statsmodels.\n",
      "Scraping wordcloud...\n",
      "Have 6 members for wordcloud.\n",
      "Scraping librosa...\n",
      "Have 233 members for librosa.\n",
      "Scraping psutil...\n",
      "Have 119 members for psutil.\n",
      "Scraping chardet...\n",
      "Have 69 members for chardet.\n",
      "Scraping textblob...\n",
      "Have 56 members for textblob.\n",
      "Scraping xlwt...\n",
      "Have 16 members for xlwt.\n",
      "Scraping dateutil...\n",
      "Have 48 members for dateutil.\n",
      "Scraping scipy...\n",
      "Have 2439 members for scipy.\n",
      "Scraping seaborn...\n",
      "Have 100 members for seaborn.\n",
      "Scraping cryptography...\n",
      "Have 437 members for cryptography.\n",
      "Scraping pandas...\n",
      "Have 312 members for pandas.\n",
      "Scraping numpy...\n",
      "Have 1258 members for numpy.\n",
      "Scraping sklearn...\n",
      "Have 633 members for sklearn.\n",
      "Scraping matplotlib...\n",
      "Have 1130 members for matplotlib.\n",
      "Scraping sympy...\n",
      "Have 2948 members for sympy.\n",
      "Scraping requests...\n",
      "Have 49 members for requests.\n",
      "Scraping bs4...\n",
      "Have 94 members for bs4.\n",
      "Scraping folium...\n",
      "Have 130 members for folium.\n"
     ]
    }
   ],
   "source": [
    "# download the members of the libraries\n",
    "\n",
    "sphinx_scraped = {}\n",
    "for library in inventory_urls:\n",
    "    try:\n",
    "        info = get_library_objects(library)\n",
    "        sphinx_scraped[library] = info\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {library}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69ce025",
   "metadata": {},
   "source": [
    "## **3.** Scrape members for the 3 remaining libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbba2ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining = {\n",
    "    \"nltk\": {\n",
    "        \"url\": \"https://www.nltk.org/py-modindex.html\",\n",
    "        \"version\": \"3.8.1\",\n",
    "    },\n",
    "    \"tensorflow\": {\n",
    "        \"url\": \"https://www.tensorflow.org/api_docs/python/tf\",\n",
    "        \"version\": \"2.6.0\",\n",
    "    },\n",
    "    \"lxml\": {\n",
    "        \"urls\": [\n",
    "            \"https://lxml.de/apidoc/index.html\",\n",
    "            \"https://lxml.de/apidoc/lxml.html.html\",\n",
    "            \"https://lxml.de/apidoc/lxml.isoschematron.html\",\n",
    "        ],\n",
    "        \"version\": \"4.6.3\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b5de245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to access the html content of documentation pages\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "def get_html_soup(url: str) -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    Fetch the HTML content from the given URL and return a BeautifulSoup object.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise an error for bad responses\n",
    "    return BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36cf0944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 355 members for nltk:\n",
      "\t['nltk', 'nltk.app', 'nltk.app.chartparser_app', 'nltk.app.chunkparser_app', 'nltk.app.collocations_app']\n"
     ]
    }
   ],
   "source": [
    "nltk_soup = get_html_soup(remaining[\"nltk\"][\"url\"])\n",
    "\n",
    "nltk_members = {\"nltk\"}\n",
    "# extract all links from the nltk module index page\n",
    "for a in nltk_soup.find_all(\"a\", href=True):\n",
    "    name = a.text.strip()\n",
    "\n",
    "    # filter entries that look like nltk module paths\n",
    "    if name.startswith(\"nltk.\"):\n",
    "        nltk_members.add(name)\n",
    "\n",
    "nltk_members = sorted(nltk_members)\n",
    "remaining[\"nltk\"][\"modules\"] = sorted(set(m.split(\".\")[0] for m in nltk_members))\n",
    "remaining[\"nltk\"][\"members\"] = nltk_members\n",
    "print(f\"Have {len(nltk_members)} members for nltk:\\n\\t{nltk_members[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "719a2b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 4377 members for tensorflow:\n",
      "\t['tensorflow.AggregationMethod', 'tensorflow.CriticalSection', 'tensorflow.DeviceSpec', 'tensorflow.GradientTape', 'tensorflow.Graph', 'tensorflow.IndexedSlices', 'tensorflow.IndexedSlicesSpec', 'tensorflow.Module', 'tensorflow.Operation', 'tensorflow.OptionalSpec']\n"
     ]
    }
   ],
   "source": [
    "tf_soup = get_html_soup(remaining[\"tensorflow\"][\"url\"])\n",
    "\n",
    "tf_members = set()\n",
    "# extract links from expandable navigation bar\n",
    "for div in tf_soup.select(\"li.devsite-nav-expandable\"):\n",
    "    # get top level module name from the toggle title span\n",
    "    reference = div.select_one(\"span.devsite-nav-text\")\n",
    "    if not reference or not reference.text.startswith(\"tf\"):\n",
    "        continue\n",
    "\n",
    "    # clean up the module name\n",
    "    title_text = reference.text.strip().replace(\"\\u200b\", \"\").replace(\" \", \"\")\n",
    "    tf_module = title_text.replace(\"tf\", \"tensorflow\")\n",
    "\n",
    "    # within the expandable div, find all links to members\n",
    "    for a in div.select(\"li.devsite-nav-item a.devsite-nav-title\"):\n",
    "        member_text = a.select_one(\"span.devsite-nav-text\").get_text().strip()\n",
    "        member_text = member_text.replace(\"\\u200b\", \"\").replace(\" \", \"\")\n",
    "\n",
    "        # skip overview entries\n",
    "        if member_text.lower() == \"overview\":\n",
    "            continue\n",
    "\n",
    "        # add full module name\n",
    "        tf_members.add(f\"{tf_module}.{member_text}\")\n",
    "\n",
    "tf_members = sorted(tf_members)\n",
    "remaining[\"tensorflow\"][\"modules\"] = sorted(set(m.split(\".\")[0] for m in tf_members))\n",
    "remaining[\"tensorflow\"][\"members\"] = tf_members\n",
    "print(f\"Have {len(tf_members)} members for tensorflow:\\n\\t{tf_members[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29e1abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method to scrape lxml documentation page\n",
    "def get_lxml_members(url: str, package: str, top_level: int) -> set:\n",
    "    _lxml_soup = get_html_soup(url=url)\n",
    "    _lxml_members = set()\n",
    "\n",
    "    # extract all top level modules\n",
    "    for top in _lxml_soup.select(f\"li.toctree-l{top_level}\"):\n",
    "        reference = top.select_one(\"a.reference\")\n",
    "        module = reference.text.strip() if reference else \"\"\n",
    "        module = module.split(\" \")[0]\n",
    "        if (\n",
    "            not module\n",
    "            or not module.startswith(f\"{package}.\")\n",
    "            or module.startswith(f\"{package}._\")\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        _lxml_members.add(module)\n",
    "\n",
    "        # extract all members of the top level modules\n",
    "        for a in top.select(f\"li.toctree-l{top_level + 1} > a\"):\n",
    "            name = a.text.strip()\n",
    "            # Some names include trailing ' — description'; strip that\n",
    "            if name.startswith(\"_\") or name.lower() in [\n",
    "                \"submodules\",\n",
    "                \"module contents\",\n",
    "            ]:\n",
    "                continue\n",
    "\n",
    "            name = name.split(\"—\", 1)[0].strip().rstrip(\"()\")\n",
    "            _lxml_members.add(f\"{module}.{name}\")\n",
    "\n",
    "    # extract all members of the module itself\n",
    "    for dt in _lxml_soup.select(\"dt.sig.sig-object.py\"):\n",
    "        if (_id := dt.get(\"id\")) and dt.select_one(\"span.descclassname\"):\n",
    "            if _id.startswith(f\"{package}.\") and not _id.startswith(f\"{package}._\"):\n",
    "                _lxml_members.add(_id)\n",
    "\n",
    "    return _lxml_members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db9cb31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 391 members for lxml:\n",
      "\t['lxml', 'lxml.ElementInclude', 'lxml.ElementInclude.FatalIncludeError', 'lxml.ElementInclude.LimitedRecursiveIncludeError', 'lxml.ElementInclude.default_loader', 'lxml.ElementInclude.include', 'lxml.builder', 'lxml.builder.ElementMaker', 'lxml.cssselect', 'lxml.doctestcompare']\n"
     ]
    }
   ],
   "source": [
    "# some manually scraped members\n",
    "lxml_members = {\"lxml\", \"lxml.get_include\"}\n",
    "\n",
    "lxml_members.update(\n",
    "    get_lxml_members(\n",
    "        url=remaining[\"lxml\"][\"urls\"][0],\n",
    "        package=\"lxml\",\n",
    "        top_level=3,\n",
    "    )\n",
    ")\n",
    "lxml_members.update(\n",
    "    get_lxml_members(\n",
    "        url=remaining[\"lxml\"][\"urls\"][1],\n",
    "        package=\"lxml.html\",\n",
    "        top_level=1,\n",
    "    )\n",
    ")\n",
    "lxml_members.update(\n",
    "    get_lxml_members(\n",
    "        url=remaining[\"lxml\"][\"urls\"][2],\n",
    "        package=\"lxml.isoschematron\",\n",
    "        top_level=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "lxml_members = sorted(lxml_members)\n",
    "remaining[\"lxml\"][\"modules\"] = sorted(set(m.split(\".\")[0] for m in lxml_members))\n",
    "remaining[\"lxml\"][\"members\"] = lxml_members\n",
    "print(f\"Have {len(lxml_members)} members for lxml:\\n\\t{lxml_members[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edb2710",
   "metadata": {},
   "source": [
    "## **4.** Save all of the documentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2070eb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have data for all 30 libraries:\n",
      "\t['bs4', 'chardet', 'cryptography', 'dateutil', 'django', 'folium', 'librosa', 'lxml', 'matplotlib', 'nltk', 'numpy', 'openpyxl', 'pandas', 'psutil', 'pytesseract', 'pytz', 'regex', 'requests', 'scipy', 'seaborn', 'sklearn', 'statsmodels', 'sympy', 'tensorflow', 'textblob', 'texttable', 'wordcloud', 'wordninja', 'xlwt', 'xmltodict']\n"
     ]
    }
   ],
   "source": [
    "from llm_cgr import save_json\n",
    "from datetime import datetime\n",
    "\n",
    "final_data = {\n",
    "    **manually_scraped,\n",
    "    **sphinx_scraped,\n",
    "    **remaining,\n",
    "}\n",
    "\n",
    "for library in DOCUMENTED_LIBRARIES:\n",
    "    assert library in final_data, f\"Missing documentation for {library}!\"\n",
    "\n",
    "print(\n",
    "    f\"Have data for all {len(DOCUMENTED_LIBRARIES)} libraries:\\n\\t{DOCUMENTED_LIBRARIES}\"\n",
    ")\n",
    "save_json(\n",
    "    data={\n",
    "        \"datetime\": datetime.now().isoformat(),\n",
    "        \"data\": final_data,\n",
    "    },\n",
    "    file_path=\"../data/libraries/documentation.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f3b373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
