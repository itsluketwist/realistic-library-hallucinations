{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d384ca",
   "metadata": {},
   "source": [
    "# Download library documentation *(RQ1, RQ2, RQ3)*\n",
    "\n",
    "Download the full API reference documentation for each external library in our processed BigCodeBench dataset.\n",
    "\n",
    "This documentation will provide the ground truth necessary for determining library member hallucinations.\n",
    "\n",
    "We download the latest version of each libraries documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c60ed3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need documentation for 30 libraries:\n",
      "\t['bs4', 'chardet', 'cryptography', 'dateutil', 'django', 'folium', 'librosa', 'lxml', 'matplotlib', 'nltk', 'numpy', 'openpyxl', 'pandas', 'psutil', 'pytesseract', 'pytz', 'regex', 'requests', 'scipy', 'seaborn', 'sklearn', 'statsmodels', 'sympy', 'tensorflow', 'textblob', 'texttable', 'wordcloud', 'wordninja', 'xlwt', 'xmltodict']\n"
     ]
    }
   ],
   "source": [
    "# get list of libraries we need for the study\n",
    "\n",
    "from src.constants import DOCUMENTED_LIBRARIES\n",
    "\n",
    "print(\n",
    "    f\"Need documentation for {len(DOCUMENTED_LIBRARIES)} libraries:\\n\\t{DOCUMENTED_LIBRARIES}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00efa1ae",
   "metadata": {},
   "source": [
    "## **1.** Manually download 6 smaller libraries without parsable documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "893e8ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 6 manually scraped libraries.\n"
     ]
    }
   ],
   "source": [
    "# small libraries, scraped manually from the source code\n",
    "\n",
    "manually_scraped = {\n",
    "    \"wordninja\": {\n",
    "        \"url\": \"https://github.com/keredson/wordninja/blob/master/wordninja.py\",\n",
    "        \"version\": \"2.0.0\",\n",
    "        \"modules\": [\n",
    "            \"wordninja\",\n",
    "        ],\n",
    "        \"members\": [\n",
    "            \"wordninja\",\n",
    "            \"wordninja.LanguageModel\",\n",
    "            \"wordninja.DEFAULT_LANGUAGE_MODEL\",\n",
    "            \"wordninja.split\",\n",
    "        ],\n",
    "    },\n",
    "    \"texttable\": {\n",
    "        \"url\": \"https://github.com/foutaise/texttable/blob/master/texttable.py\",\n",
    "        \"version\": \"1.7.0\",\n",
    "        \"modules\": [\n",
    "            \"texttable\",\n",
    "        ],\n",
    "        \"members\": [\n",
    "            \"texttable\",\n",
    "            \"texttable.Texttable\",\n",
    "            \"texttable.ArraySizeError\",\n",
    "            \"texttable.obj2unicode\",\n",
    "            \"texttable.len\",\n",
    "        ],\n",
    "    },\n",
    "    \"xmltodict\": {\n",
    "        \"url\": \"https://github.com/martinblech/xmltodict/blob/master/xmltodict.py\",\n",
    "        \"version\": \"0.14.2\",\n",
    "        \"modules\": [\n",
    "            \"xmltodict\",\n",
    "        ],\n",
    "        \"members\": [\n",
    "            \"xmltodict\",\n",
    "            \"xmltodict.parse\",\n",
    "            \"xmltodict.unparse\",\n",
    "            \"xmltodict.ParsingInterrupted\",\n",
    "        ],\n",
    "    },\n",
    "    \"regex\": {\n",
    "        \"url\": \"https://github.com/mrabarnett/mrab-regex/blob/hg/regex_3/regex.py\",\n",
    "        \"version\": \"2.5.153\",\n",
    "        \"modules\": [\n",
    "            \"regex\",\n",
    "        ],\n",
    "        \"members\": [\n",
    "            \"regex\",\n",
    "            \"regex.cache_all\",\n",
    "            \"regex.compile\",\n",
    "            \"regex.DEFAULT_VERSION\",\n",
    "            \"regex.escape\",\n",
    "            \"regex.findall\",\n",
    "            \"regex.finditer\",\n",
    "            \"regex.fullmatch\",\n",
    "            \"regex.match\",\n",
    "            \"regex.purge\",\n",
    "            \"regex.search\",\n",
    "            \"regex.split\",\n",
    "            \"regex.splititer\",\n",
    "            \"regex.sub\",\n",
    "            \"regex.subf\",\n",
    "            \"regex.subfn\",\n",
    "            \"regex.subn\",\n",
    "            \"regex.template\",\n",
    "            \"regex.Scanner\",\n",
    "            \"regex.A\",\n",
    "            \"regex.ASCII\",\n",
    "            \"regex.B\",\n",
    "            \"regex.BESTMATCH\",\n",
    "            \"regex.D\",\n",
    "            \"regex.DEBUG\",\n",
    "            \"regex.E\",\n",
    "            \"regex.ENHANCEMATCH\",\n",
    "            \"regex.S\",\n",
    "            \"regex.DOTALL\",\n",
    "            \"regex.F\",\n",
    "            \"regex.FULLCASE\",\n",
    "            \"regex.I\",\n",
    "            \"regex.IGNORECASE\",\n",
    "            \"regex.L\",\n",
    "            \"regex.LOCALE\",\n",
    "            \"regex.M\",\n",
    "            \"regex.MULTILINE\",\n",
    "            \"regex.P\",\n",
    "            \"regex.POSIX\",\n",
    "            \"regex.R\",\n",
    "            \"regex.REVERSE\",\n",
    "            \"regex.T\",\n",
    "            \"regex.TEMPLATE\",\n",
    "            \"regex.U\",\n",
    "            \"regex.UNICODE\",\n",
    "            \"regex.V0\",\n",
    "            \"regex.VERSION0\",\n",
    "            \"regex.V1\",\n",
    "            \"regex.VERSION1\",\n",
    "            \"regex.X\",\n",
    "            \"regex.VERBOSE\",\n",
    "            \"regex.W\",\n",
    "            \"regex.WORD\",\n",
    "            \"regex.error\",\n",
    "            \"regex.Regex\",\n",
    "            \"regex.__version__\",\n",
    "            \"regex.__doc__\",\n",
    "            \"regex.RegexFlag\",\n",
    "        ],\n",
    "    },\n",
    "    \"pytz\": {\n",
    "        \"url\": \"https://github.com/stub42/pytz/blob/master/src/pytz/__init__.py\",\n",
    "        \"version\": \"2025.2\",\n",
    "        \"modules\": [\n",
    "            \"pytz\",\n",
    "        ],\n",
    "        \"members\": [\n",
    "            \"pytz\",\n",
    "            \"pytz.timezone\",\n",
    "            \"pytz.utc\",\n",
    "            \"pytz.country_timezones\",\n",
    "            \"pytz.country_names\",\n",
    "            \"pytz.all_timezones\",\n",
    "            \"pytz.all_timezones_set\",\n",
    "            \"pytz.common_timezones\",\n",
    "            \"pytz.common_timezones_set\",\n",
    "            \"pytz.BaseTzInfo\",\n",
    "            \"pytz.FixedOffset\",\n",
    "            \"pytz.AmbiguousTimeError\",\n",
    "            \"pytz.InvalidTimeError\",\n",
    "            \"pytz.NonExistentTimeError\",\n",
    "            \"pytz.UnknownTimeZoneError\",\n",
    "            \"pytz.exceptions\",\n",
    "            \"pytz.exceptions.AmbiguousTimeError\",\n",
    "            \"pytz.exceptions.InvalidTimeError\",\n",
    "            \"pytz.exceptions.NonExistentTimeError\",\n",
    "            \"pytz.exceptions.UnknownTimeZoneError\",\n",
    "            \"pytz.tzinfo\",\n",
    "            \"pytz.tzinfo.memorized_timedelta\",\n",
    "            \"pytz.tzinfo.memorized_datetime\",\n",
    "            \"pytz.tzinfo.memorized_ttinfo\",\n",
    "            \"pytz.tzinfo.BaseTzInfo\",\n",
    "            \"pytz.tzinfo.StaticTzInfo\",\n",
    "            \"pytz.tzinfo.DstTzInfo\",\n",
    "            \"pytz.tzinfo.unpickler\",\n",
    "            \"pytz.tzfile\",\n",
    "            \"pytz.tzfile.build_tzinfo\",\n",
    "            \"pytz.reference\",\n",
    "            \"pytz.reference.FixedOffset\",\n",
    "            \"pytz.reference.LocalTimezone\",\n",
    "            \"pytz.reference.USTimeZone\",\n",
    "            \"pytz.reference.Eastern\",\n",
    "            \"pytz.reference.Central\",\n",
    "            \"pytz.reference.Mountain\",\n",
    "            \"pytz.reference.Pacific\",\n",
    "            \"pytz.reference.UTC\",\n",
    "            \"pytz.lazy\",\n",
    "            \"pytz.lazy.LazyDict\",\n",
    "            \"pytz.lazy.LazyList\",\n",
    "            \"pytz.lazy.LazySet\",\n",
    "        ],\n",
    "    },\n",
    "    \"pytesseract\": {\n",
    "        \"url\": \"https://github.com/madmaze/pytesseract\",\n",
    "        \"version\": \"0.3.13\",\n",
    "        \"modules\": [\n",
    "            \"pytesseract\",\n",
    "        ],\n",
    "        \"members\": [\n",
    "            \"pytesseract\",\n",
    "            \"pytesseract.DEFAULT_ENCODING\",\n",
    "            \"pytesseract.LANG_PATTERN\",\n",
    "            \"pytesseract.RGB_MODE\",\n",
    "            \"pytesseract.SUPPORTED_FORMATS\",\n",
    "            \"pytesseract.OSD_KEYS\",\n",
    "            \"pytesseract.EXTENTION_TO_CONFIG\",\n",
    "            \"pytesseract.TESSERACT_MIN_VERSION\",\n",
    "            \"pytesseract.TESSERACT_ALTO_VERSION\",\n",
    "            \"pytesseract.Output\",\n",
    "            \"pytesseract.PandasNotSupported\",\n",
    "            \"pytesseract.TesseractError\",\n",
    "            \"pytesseract.TesseractNotFoundError\",\n",
    "            \"pytesseract.TSVNotSupported\",\n",
    "            \"pytesseract.ALTONotSupported\",\n",
    "            \"pytesseract.kill\",\n",
    "            \"pytesseract.timeout_manager\",\n",
    "            \"pytesseract.run_once\",\n",
    "            \"pytesseract.get_errors\",\n",
    "            \"pytesseract.cleanup\",\n",
    "            \"pytesseract.prepare\",\n",
    "            \"pytesseract.save\",\n",
    "            \"pytesseract.subprocess_args\",\n",
    "            \"pytesseract.run_tesseract\",\n",
    "            \"pytesseract.run_and_get_multiple_output\",\n",
    "            \"pytesseract.run_and_get_output\",\n",
    "            \"pytesseract.file_to_dict\",\n",
    "            \"pytesseract.is_valid\",\n",
    "            \"pytesseract.osd_to_dict\",\n",
    "            \"pytesseract.get_languages\",\n",
    "            \"pytesseract.get_tesseract_version\",\n",
    "            \"pytesseract.image_to_string\",\n",
    "            \"pytesseract.image_to_pdf_or_hocr\",\n",
    "            \"pytesseract.image_to_alto_xml\",\n",
    "            \"pytesseract.image_to_boxes\",\n",
    "            \"pytesseract.get_pandas_output\",\n",
    "            \"pytesseract.image_to_data\",\n",
    "            \"pytesseract.image_to_osd\",\n",
    "            \"pytesseract.main\",\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"Have {len(manually_scraped)} manually scraped libraries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6c260e",
   "metadata": {},
   "source": [
    "## **2.** Automatically download the inventory of 21 libraries using Sphinx / readthedocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aca33b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the inventory urls for libraries with sphinx / readthedocs documentation\n",
    "\n",
    "inventory_urls = {\n",
    "    \"bs4\": \"https://www.crummy.com/software/BeautifulSoup/bs4/doc/objects.inv\",\n",
    "    \"chardet\": \"https://chardet.readthedocs.io/en/latest/objects.inv\",\n",
    "    \"cryptography\": \"https://cryptography.io/en/latest/objects.inv\",\n",
    "    \"dateutil\": \"https://dateutil.readthedocs.io/en/stable/objects.inv\",  #\n",
    "    \"django\": \"https://docs.djangoproject.com/en/stable/objects.inv\",\n",
    "    \"folium\": \"https://python-visualization.github.io/folium/latest/objects.inv\",\n",
    "    \"librosa\": \"https://librosa.org/doc/latest/objects.inv\",\n",
    "    \"matplotlib\": \"https://matplotlib.org/stable/objects.inv\",\n",
    "    \"numpy\": \"https://numpy.org/doc/stable/objects.inv\",  #\n",
    "    \"openpyxl\": \"https://openpyxl.readthedocs.io/en/latest/objects.inv\",  #\n",
    "    \"pandas\": \"https://pandas.pydata.org/pandas-docs/stable/objects.inv\",  #\n",
    "    \"psutil\": \"https://psutil.readthedocs.io/en/latest/objects.inv\",\n",
    "    \"requests\": \"https://docs.python-requests.org/en/latest/objects.inv\",\n",
    "    \"scipy\": \"https://docs.scipy.org/doc/scipy/objects.inv\",  #\n",
    "    \"seaborn\": \"https://seaborn.pydata.org/objects.inv\",\n",
    "    \"sklearn\": \"https://scikit-learn.org/stable/objects.inv\",  #\n",
    "    \"statsmodels\": \"https://www.statsmodels.org/stable/objects.inv\",\n",
    "    \"sympy\": \"https://docs.sympy.org/latest/objects.inv\",  #\n",
    "    \"textblob\": \"https://textblob.readthedocs.io/en/latest/objects.inv\",  #\n",
    "    \"wordcloud\": \"https://amueller.github.io/word_cloud/objects.inv\",\n",
    "    \"xlwt\": \"https://xlwt.readthedocs.io/en/latest/objects.inv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a51f14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method to fetch the inventory and extract importable python objects\n",
    "\n",
    "import sphobjinv as soi\n",
    "\n",
    "python_objects = {\n",
    "    \"module\",\n",
    "    \"class\",\n",
    "    \"exception\",\n",
    "    \"function\",\n",
    "    \"data\",\n",
    "    # all of these are parts of classes, and not importable on their own, so ignored\n",
    "    # \"method\", \"attribute\", \"property\",\n",
    "}\n",
    "\n",
    "\n",
    "def get_library_objects(library: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fetch the inventory from the given URL and return a dictionary with library info.\n",
    "    \"\"\"\n",
    "    # download the inventory\n",
    "    print(f\"Scraping {library}...\")\n",
    "    inv = soi.Inventory(url=inventory_urls[library])\n",
    "\n",
    "    # filter to only importable python objects\n",
    "    base_members = set()\n",
    "    for obj in inv.objects:\n",
    "        if obj.domain == \"py\" and obj.role in python_objects:\n",
    "            base_members.add(obj.name)\n",
    "\n",
    "    # filter the members to catch any excessive inclusions by the sphinx file\n",
    "    final_members = {library}\n",
    "    for member in base_members:\n",
    "        # sometimes other library members are included in the inventory, which we want to ignore\n",
    "        if any(\n",
    "            member.startswith(f\"{_m}.\") for _m in set(DOCUMENTED_LIBRARIES) - {library}\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        # ignore any private members\n",
    "        if any(_section.startswith(\"_\") for _section in member.split(\".\")):\n",
    "            continue\n",
    "\n",
    "        # check if member marked as a module should instead have a parent\n",
    "        if \".\" not in member:\n",
    "            if any((member in m) and m != member for m in base_members):\n",
    "                final_members.add(f\"{library}.{member}\")\n",
    "            else:\n",
    "                final_members.add(member)\n",
    "            continue\n",
    "\n",
    "        # skip any members that are known errors\n",
    "        if any(\n",
    "            member.startswith(f\"{_skip}\") for _skip in [\"asgiref\", \"object\", \"builtins\"]\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        # otherwise add the member as is\n",
    "        final_members.add(member)\n",
    "\n",
    "    print(f\"Have {len(final_members)} members for {library}.\")\n",
    "    return {\n",
    "        \"url\": inventory_urls[library],\n",
    "        \"version\": inv.version,\n",
    "        \"modules\": sorted(set(m.split(\".\")[0] for m in final_members)),\n",
    "        \"members\": sorted(final_members),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80876336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping bs4...\n",
      "Have 94 members for bs4.\n",
      "Scraping chardet...\n",
      "Have 69 members for chardet.\n",
      "Scraping cryptography...\n",
      "Have 437 members for cryptography.\n",
      "Scraping dateutil...\n",
      "Have 48 members for dateutil.\n",
      "Scraping django...\n",
      "Have 1162 members for django.\n",
      "Scraping folium...\n",
      "Have 130 members for folium.\n",
      "Scraping librosa...\n",
      "Have 233 members for librosa.\n",
      "Scraping matplotlib...\n",
      "Have 1130 members for matplotlib.\n",
      "Scraping numpy...\n",
      "Have 1258 members for numpy.\n",
      "Scraping openpyxl...\n",
      "Have 800 members for openpyxl.\n",
      "Scraping pandas...\n",
      "Have 312 members for pandas.\n",
      "Scraping psutil...\n",
      "Have 119 members for psutil.\n",
      "Scraping requests...\n",
      "Have 49 members for requests.\n",
      "Scraping scipy...\n",
      "Have 2439 members for scipy.\n",
      "Scraping seaborn...\n",
      "Have 100 members for seaborn.\n",
      "Scraping sklearn...\n",
      "Have 633 members for sklearn.\n",
      "Scraping statsmodels...\n",
      "Have 909 members for statsmodels.\n",
      "Scraping sympy...\n",
      "Have 2948 members for sympy.\n",
      "Scraping textblob...\n",
      "Have 56 members for textblob.\n",
      "Scraping wordcloud...\n",
      "Have 6 members for wordcloud.\n",
      "Scraping xlwt...\n",
      "Have 16 members for xlwt.\n"
     ]
    }
   ],
   "source": [
    "# download the members of the libraries\n",
    "\n",
    "sphinx_scraped = {}\n",
    "for library in inventory_urls:\n",
    "    try:\n",
    "        info = get_library_objects(library)\n",
    "        sphinx_scraped[library] = info\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {library}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf01037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add some missing members to the sphinx scraped libraries\n",
    "\n",
    "# textblob top level imports not in documentation\n",
    "sphinx_scraped[\"textblob\"][\"members\"].extend(\n",
    "    [\n",
    "        \"textblob.TextBlob\",\n",
    "        \"textblob.WordList\",\n",
    "        \"textblob.Word\",\n",
    "        \"textblob.Sentence\",\n",
    "        \"textblob.Blobber\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# numpy has known alias shortcut\n",
    "sphinx_scraped[\"numpy\"][\"members\"].extend(\n",
    "    [\n",
    "        \"numpy.abs\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# dateutil parser functions are missed\n",
    "sphinx_scraped[\"dateutil\"][\"members\"].extend(\n",
    "    [\n",
    "        \"dateutil.parser.parse\",\n",
    "        \"dateutil.parser.isoparse\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# openpyxl top level imports not in documentation\n",
    "sphinx_scraped[\"openpyxl\"][\"members\"].extend(\n",
    "    [\n",
    "        \"openpyxl.NUMPY\",\n",
    "        \"openpyxl.DEFUSEDXML\",\n",
    "        \"openpyxl.LXML\",\n",
    "        \"openpyxl.Workbook\",\n",
    "        \"openpyxl.load_workbook\",\n",
    "        \"openpyxl.open\",\n",
    "        \"openpyxl.constants\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# sympy allows everything to be imported from the top level\n",
    "# fmt: off\n",
    "sphinx_scraped[\"sympy\"][\"members\"].extend(\n",
    "    [\n",
    "        f\"sympy.{m}\"\n",
    "        for m in [\n",
    "            # sympy.core\n",
    "            'sympify', 'SympifyError', 'cacheit', 'Basic', 'Atom',\n",
    "            'preorder_traversal', 'S', 'Expr', 'AtomicExpr', 'UnevaluatedExpr',\n",
    "            'Symbol', 'Wild', 'Dummy', 'symbols', 'var', 'Number', 'Float',\n",
    "            'Rational', 'Integer', 'NumberSymbol', 'RealNumber', 'igcd', 'ilcm',\n",
    "            'seterr', 'E', 'I', 'nan', 'oo', 'pi', 'zoo', 'AlgebraicNumber', 'comp',\n",
    "            'mod_inverse', 'Pow', 'integer_nthroot', 'integer_log', 'trailing', 'Mul', 'prod',\n",
    "            'Add', 'Mod', 'Rel', 'Eq', 'Ne', 'Lt', 'Le', 'Gt', 'Ge', 'Equality',\n",
    "            'GreaterThan', 'LessThan', 'Unequality', 'StrictGreaterThan',\n",
    "            'StrictLessThan', 'vectorize', 'Lambda', 'WildFunction', 'Derivative',\n",
    "            'diff', 'FunctionClass', 'Function', 'Subs', 'expand', 'PoleError',\n",
    "            'count_ops', 'expand_mul', 'expand_log', 'expand_func', 'expand_trig',\n",
    "            'expand_complex', 'expand_multinomial', 'nfloat', 'expand_power_base',\n",
    "            'expand_power_exp', 'arity', 'PrecisionExhausted', 'N', 'evalf', 'Tuple',\n",
    "            'Dict', 'gcd_terms', 'factor_terms', 'factor_nc', 'evaluate', 'Catalan',\n",
    "            'EulerGamma', 'GoldenRatio', 'TribonacciConstant', 'bottom_up', 'use',\n",
    "            'postorder_traversal', 'default_sort_key', 'ordered', 'num_digits',\n",
    "\n",
    "            # sympy.logic\n",
    "            'to_cnf', 'to_dnf', 'to_nnf', 'And', 'Or', 'Not', 'Xor', 'Nand', 'Nor',\n",
    "            'Implies', 'Equivalent', 'ITE', 'POSform', 'SOPform', 'simplify_logic',\n",
    "            'bool_map', 'true', 'false', 'satisfiable',\n",
    "\n",
    "            # sympy.assumptions\n",
    "            'AppliedPredicate', 'Predicate', 'AssumptionsContext', 'assuming', 'Q',\n",
    "            'ask', 'register_handler', 'remove_handler', 'refine',\n",
    "\n",
    "            # sympy.polys\n",
    "            'Poly', 'PurePoly', 'poly_from_expr', 'parallel_poly_from_expr', 'degree',\n",
    "            'total_degree', 'degree_list', 'LC', 'LM', 'LT', 'pdiv', 'prem', 'pquo',\n",
    "            'pexquo', 'div', 'rem', 'quo', 'exquo', 'half_gcdex', 'gcdex', 'invert',\n",
    "            'subresultants', 'resultant', 'discriminant', 'cofactors', 'gcd_list',\n",
    "            'gcd', 'lcm_list', 'lcm', 'terms_gcd', 'trunc', 'monic', 'content',\n",
    "            'primitive', 'compose', 'decompose', 'sturm', 'gff_list', 'gff',\n",
    "            'sqf_norm', 'sqf_part', 'sqf_list', 'sqf', 'factor_list', 'factor',\n",
    "            'intervals', 'refine_root', 'count_roots', 'all_roots', 'real_roots',\n",
    "            'nroots', 'ground_roots', 'nth_power_roots_poly', 'cancel', 'reduced',\n",
    "            'groebner', 'is_zero_dimensional', 'GroebnerBasis', 'poly', 'symmetrize',\n",
    "            'horner', 'interpolate', 'rational_interpolate', 'viete', 'together',\n",
    "            'BasePolynomialError', 'ExactQuotientFailed', 'PolynomialDivisionFailed',\n",
    "            'OperationNotSupported', 'HeuristicGCDFailed', 'HomomorphismFailed',\n",
    "            'IsomorphismFailed', 'ExtraneousFactors', 'EvaluationFailed',\n",
    "            'RefinementFailed', 'CoercionFailed', 'NotInvertible', 'NotReversible',\n",
    "            'NotAlgebraic', 'DomainError', 'PolynomialError', 'UnificationFailed',\n",
    "            'GeneratorsError', 'GeneratorsNeeded', 'ComputationFailed',\n",
    "            'UnivariatePolynomialError', 'MultivariatePolynomialError',\n",
    "            'PolificationFailed', 'OptionError', 'FlagError', 'minpoly',\n",
    "            'minimal_polynomial', 'primitive_element', 'field_isomorphism',\n",
    "            'to_number_field', 'isolate', 'round_two', 'prime_decomp',\n",
    "            'prime_valuation', 'galois_group', 'itermonomials', 'Monomial', 'lex', 'grlex',\n",
    "            'grevlex', 'ilex', 'igrlex', 'igrevlex', 'CRootOf', 'rootof', 'RootOf',\n",
    "            'ComplexRootOf', 'RootSum', 'roots', 'Domain', 'FiniteField',\n",
    "            'IntegerRing', 'RationalField', 'RealField', 'ComplexField',\n",
    "            'PythonFiniteField', 'GMPYFiniteField', 'PythonIntegerRing',\n",
    "            'GMPYIntegerRing', 'PythonRational', 'GMPYRationalField',\n",
    "            'AlgebraicField', 'PolynomialRing', 'FractionField', 'ExpressionDomain',\n",
    "            'FF_python', 'FF_gmpy', 'ZZ_python', 'ZZ_gmpy', 'QQ_python', 'QQ_gmpy',\n",
    "            'GF', 'FF', 'ZZ', 'QQ', 'ZZ_I', 'QQ_I', 'RR', 'CC', 'EX', 'EXRAW',\n",
    "            'construct_domain', 'swinnerton_dyer_poly', 'cyclotomic_poly',\n",
    "            'symmetric_poly', 'random_poly', 'interpolating_poly', 'jacobi_poly',\n",
    "            'chebyshevt_poly', 'chebyshevu_poly', 'hermite_poly', 'hermite_prob_poly',\n",
    "            'legendre_poly', 'laguerre_poly', 'apart', 'apart_list', 'assemble_partfrac_list',\n",
    "            'Options', 'ring', 'xring', 'vring', 'sring', 'field', 'xfield', 'vfield',\n",
    "            'sfield',\n",
    "\n",
    "            # sympy.series\n",
    "            'Order', 'O', 'limit', 'Limit', 'gruntz', 'series', 'approximants',\n",
    "            'pade_approximant', 'residue', 'EmptySequence', 'SeqPer', 'SeqFormula',\n",
    "            'sequence', 'SeqAdd', 'SeqMul', 'fourier_series', 'fps', 'difference_delta',\n",
    "            'limit_seq',\n",
    "\n",
    "            # sympy.functions\n",
    "            'factorial', 'factorial2', 'rf', 'ff', 'binomial', 'RisingFactorial',\n",
    "            'FallingFactorial', 'subfactorial', 'carmichael', 'fibonacci', 'lucas',\n",
    "            'motzkin', 'tribonacci', 'harmonic', 'bernoulli', 'bell', 'euler', 'catalan',\n",
    "            'genocchi', 'andre', 'partition',  'divisor_sigma', 'legendre_symbol', 'jacobi_symbol',\n",
    "            'kronecker_symbol', 'mobius', 'primenu', 'primeomega', 'totient', 'primepi',\n",
    "            'reduced_totient', 'sqrt', 'root', 'Min', 'Max', 'Id', 'real_root',\n",
    "            'Rem', 'cbrt', 're', 'im', 'sign', 'Abs', 'conjugate', 'arg', 'polar_lift',\n",
    "            'periodic_argument', 'unbranched_argument', 'principal_branch',\n",
    "            'transpose', 'adjoint', 'polarify', 'unpolarify', 'sin', 'cos', 'tan',\n",
    "            'sec', 'csc', 'cot', 'sinc', 'asin', 'acos', 'atan', 'asec', 'acsc',\n",
    "            'acot', 'atan2', 'exp_polar', 'exp', 'ln', 'log', 'LambertW', 'sinh',\n",
    "            'cosh', 'tanh', 'coth', 'sech', 'csch', 'asinh', 'acosh', 'atanh',\n",
    "            'acoth', 'asech', 'acsch', 'floor', 'ceiling', 'frac', 'Piecewise',\n",
    "            'piecewise_fold', 'piecewise_exclusive', 'erf', 'erfc', 'erfi', 'erf2',\n",
    "            'erfinv', 'erfcinv', 'erf2inv', 'Ei', 'expint', 'E1', 'li', 'Li', 'Si',\n",
    "            'Ci', 'Shi', 'Chi', 'fresnels', 'fresnelc', 'gamma', 'lowergamma',\n",
    "            'uppergamma', 'polygamma', 'loggamma', 'digamma', 'trigamma', 'multigamma',\n",
    "            'dirichlet_eta', 'zeta', 'lerchphi', 'polylog', 'stieltjes', 'Eijk', 'LeviCivita',\n",
    "            'KroneckerDelta', 'SingularityFunction', 'DiracDelta', 'Heaviside',\n",
    "            'bspline_basis', 'bspline_basis_set', 'interpolating_spline', 'besselj',\n",
    "            'bessely', 'besseli', 'besselk', 'hankel1', 'hankel2', 'jn', 'yn',\n",
    "            'jn_zeros', 'hn1', 'hn2', 'airyai', 'airybi', 'airyaiprime',\n",
    "            'airybiprime', 'marcumq', 'hyper', 'meijerg', 'appellf1', 'legendre',\n",
    "            'assoc_legendre', 'hermite', 'hermite_prob', 'chebyshevt', 'chebyshevu',\n",
    "            'chebyshevu_root', 'chebyshevt_root', 'laguerre', 'assoc_laguerre',\n",
    "            'gegenbauer', 'jacobi', 'jacobi_normalized', 'Ynm', 'Ynm_c', 'Znm',\n",
    "            'elliptic_k', 'elliptic_f', 'elliptic_e', 'elliptic_pi', 'beta',\n",
    "            'mathieus', 'mathieuc', 'mathieusprime', 'mathieucprime', 'riemann_xi','betainc',\n",
    "            'betainc_regularized',\n",
    "\n",
    "            # sympy.ntheory\n",
    "            'nextprime', 'prevprime', 'prime', 'primerange', 'randprime',\n",
    "            'Sieve', 'sieve', 'primorial', 'cycle_length', 'composite', 'compositepi',\n",
    "            'isprime', 'divisors', 'proper_divisors', 'factorint', 'multiplicity',\n",
    "            'perfect_power', 'pollard_pm1', 'factor_cache', 'pollard_rho', 'primefactors',\n",
    "            'divisor_count', 'proper_divisor_count',\n",
    "            'factorrat',\n",
    "            'mersenne_prime_exponent', 'is_perfect', 'is_mersenne_prime',\n",
    "            'is_abundant', 'is_deficient', 'is_amicable', 'is_carmichael', 'abundance',\n",
    "            'npartitions',\n",
    "            'is_primitive_root', 'is_quad_residue',\n",
    "            'n_order', 'sqrt_mod', 'quadratic_residues',\n",
    "            'primitive_root', 'nthroot_mod', 'is_nthpow_residue', 'sqrt_mod_iter',\n",
    "            'discrete_log', 'quadratic_congruence', 'binomial_coefficients',\n",
    "            'binomial_coefficients_list', 'multinomial_coefficients',\n",
    "            'continued_fraction_periodic', 'continued_fraction_iterator',\n",
    "            'continued_fraction_reduce', 'continued_fraction_convergents',\n",
    "            'continued_fraction', 'egyptian_fraction',\n",
    "\n",
    "            # sympy.concrete\n",
    "            'product', 'Product', 'summation', 'Sum',\n",
    "\n",
    "            # sympy.discrete\n",
    "            'fft', 'ifft', 'ntt', 'intt', 'fwht', 'ifwht', 'mobius_transform',\n",
    "            'inverse_mobius_transform', 'convolution', 'covering_product',\n",
    "            'intersecting_product',\n",
    "\n",
    "            # sympy.simplify\n",
    "            'simplify', 'hypersimp', 'hypersimilar', 'logcombine', 'separatevars',\n",
    "            'posify', 'besselsimp', 'kroneckersimp', 'signsimp',\n",
    "            'nsimplify', 'FU', 'fu', 'sqrtdenest', 'cse', 'epath', 'EPath',\n",
    "            'hyperexpand', 'collect', 'rcollect', 'radsimp', 'collect_const',\n",
    "            'fraction', 'numer', 'denom', 'trigsimp', 'exptrigsimp', 'powsimp',\n",
    "            'powdenest', 'combsimp', 'gammasimp', 'ratsimp', 'ratsimpmodprime',\n",
    "\n",
    "            # sympy.sets\n",
    "            'Set', 'Interval', 'Union', 'EmptySet', 'FiniteSet', 'ProductSet',\n",
    "            'Intersection', 'imageset', 'DisjointUnion', 'Complement', 'SymmetricDifference',\n",
    "            'ImageSet', 'Range', 'ComplexRegion', 'Reals', 'Contains', 'ConditionSet',\n",
    "            'Ordinal', 'OmegaPower', 'ord0', 'PowerSet', 'Naturals',\n",
    "            'Naturals0', 'UniversalSet', 'Integers', 'Rationals', 'Complexes',\n",
    "\n",
    "            # sympy.solvers\n",
    "            'solve', 'solve_linear_system', 'solve_linear_system_LU',\n",
    "            'solve_undetermined_coeffs', 'nsolve', 'solve_linear', 'checksol',\n",
    "            'det_quick', 'inv_quick', 'check_assumptions', 'failing_assumptions',\n",
    "            'diophantine', 'rsolve', 'rsolve_poly', 'rsolve_ratio', 'rsolve_hyper',\n",
    "            'checkodesol', 'classify_ode', 'dsolve', 'homogeneous_order',\n",
    "            'solve_poly_system', 'factor_system', 'solve_triangulated', 'pde_separate',\n",
    "            'pde_separate_add', 'pde_separate_mul', 'pdsolve', 'classify_pde',\n",
    "            'checkpdesol', 'ode_order', 'reduce_inequalities',\n",
    "            'reduce_abs_inequality', 'reduce_abs_inequalities',\n",
    "            'solve_poly_inequality', 'solve_rational_inequalities',\n",
    "            'solve_univariate_inequality', 'decompogen', 'solveset', 'linsolve',\n",
    "            'linear_eq_to_matrix', 'nonlinsolve', 'substitution',\n",
    "\n",
    "            # sympy.matrices\n",
    "            'ShapeError', 'NonSquareMatrixError', 'GramSchmidt', 'casoratian', 'diag',\n",
    "            'eye', 'hessian', 'jordan_cell', 'list2numpy', 'matrix2numpy',\n",
    "            'matrix_multiply_elementwise', 'ones', 'randMatrix', 'rot_axis1',\n",
    "            'rot_axis2', 'rot_axis3', 'symarray', 'wronskian', 'zeros',\n",
    "            'MutableDenseMatrix', 'DeferredVector', 'MatrixBase', 'Matrix',\n",
    "            'MutableMatrix', 'MutableSparseMatrix', 'banded', 'ImmutableDenseMatrix',\n",
    "            'ImmutableSparseMatrix', 'ImmutableMatrix', 'SparseMatrix', 'MatrixSlice',\n",
    "            'BlockDiagMatrix', 'BlockMatrix', 'FunctionMatrix', 'Identity', 'Inverse',\n",
    "            'MatAdd', 'MatMul', 'MatPow', 'MatrixExpr', 'MatrixSymbol', 'Trace',\n",
    "            'Transpose', 'ZeroMatrix', 'OneMatrix', 'blockcut', 'block_collapse',\n",
    "            'matrix_symbols', 'Adjoint', 'hadamard_product', 'HadamardProduct',\n",
    "            'HadamardPower', 'Determinant', 'det', 'diagonalize_vector', 'DiagMatrix',\n",
    "            'DiagonalMatrix', 'DiagonalOf', 'trace', 'DotProduct',\n",
    "            'kronecker_product', 'KroneckerProduct', 'PermutationMatrix',\n",
    "            'MatrixPermute', 'Permanent', 'per', 'rot_ccw_axis1', 'rot_ccw_axis2',\n",
    "            'rot_ccw_axis3', 'rot_givens',\n",
    "\n",
    "            # sympy.geometry\n",
    "            'Point', 'Point2D', 'Point3D', 'Line', 'Ray', 'Segment', 'Line2D',\n",
    "            'Segment2D', 'Ray2D', 'Line3D', 'Segment3D', 'Ray3D', 'Plane', 'Ellipse',\n",
    "            'Circle', 'Polygon', 'RegularPolygon', 'Triangle', 'rad', 'deg',\n",
    "            'are_similar', 'centroid', 'convex_hull', 'idiff', 'intersection',\n",
    "            'closest_points', 'farthest_points', 'GeometryError', 'Curve', 'Parabola',\n",
    "\n",
    "            # sympy.utilities\n",
    "            'flatten', 'group', 'take', 'subsets', 'variations', 'numbered_symbols',\n",
    "            'cartes', 'capture', 'dict_merge', 'prefixes', 'postfixes', 'sift',\n",
    "            'topological_sort', 'unflatten', 'has_dups', 'has_variety', 'reshape',\n",
    "            'rotations', 'filldedent', 'lambdify', 'threaded', 'xthreaded',\n",
    "            'public', 'memoize_property', 'timed',\n",
    "\n",
    "            # sympy.integrals\n",
    "            'integrate', 'Integral', 'line_integrate', 'mellin_transform',\n",
    "            'inverse_mellin_transform', 'MellinTransform', 'InverseMellinTransform',\n",
    "            'laplace_transform', 'inverse_laplace_transform', 'LaplaceTransform',\n",
    "            'laplace_correspondence', 'laplace_initial_conds',\n",
    "            'InverseLaplaceTransform', 'fourier_transform',\n",
    "            'inverse_fourier_transform', 'FourierTransform',\n",
    "            'InverseFourierTransform', 'sine_transform', 'inverse_sine_transform',\n",
    "            'SineTransform', 'InverseSineTransform', 'cosine_transform',\n",
    "            'inverse_cosine_transform', 'CosineTransform', 'InverseCosineTransform',\n",
    "            'hankel_transform', 'inverse_hankel_transform', 'HankelTransform',\n",
    "            'InverseHankelTransform', 'singularityintegrate',\n",
    "\n",
    "            # sympy.tensor\n",
    "            'IndexedBase', 'Idx', 'Indexed', 'get_contraction_structure',\n",
    "            'get_indices', 'shape', 'MutableDenseNDimArray', 'ImmutableDenseNDimArray',\n",
    "            'MutableSparseNDimArray', 'ImmutableSparseNDimArray', 'NDimArray',\n",
    "            'tensorproduct', 'tensorcontraction', 'tensordiagonal', 'derive_by_array',\n",
    "            'permutedims', 'Array', 'DenseNDimArray', 'SparseNDimArray',\n",
    "\n",
    "            # sympy.parsing\n",
    "            'parse_expr',\n",
    "\n",
    "            # sympy.calculus\n",
    "            'euler_equations', 'singularities', 'is_increasing',\n",
    "            'is_strictly_increasing', 'is_decreasing', 'is_strictly_decreasing',\n",
    "            'is_monotonic', 'finite_diff_weights', 'apply_finite_diff',\n",
    "            'differentiate_finite', 'periodicity', 'not_empty_in',\n",
    "            'AccumBounds', 'is_convex', 'stationary_points', 'minimum', 'maximum',\n",
    "\n",
    "            # sympy.algebras\n",
    "            'Quaternion',\n",
    "\n",
    "            # sympy.printing\n",
    "            'pager_print', 'pretty', 'pretty_print', 'pprint', 'pprint_use_unicode',\n",
    "            'pprint_try_use_unicode', 'latex', 'print_latex', 'multiline_latex',\n",
    "            'mathml', 'print_mathml', 'python', 'print_python', 'pycode', 'ccode',\n",
    "            'print_ccode', 'smtlib_code', 'glsl_code', 'print_glsl', 'cxxcode', 'fcode',\n",
    "            'print_fcode', 'rcode', 'print_rcode', 'jscode', 'print_jscode',\n",
    "            'julia_code', 'mathematica_code', 'octave_code', 'rust_code', 'print_gtk',\n",
    "            'preview', 'srepr', 'print_tree', 'StrPrinter', 'sstr', 'sstrrepr',\n",
    "            'TableForm', 'dotprint', 'maple_code', 'print_maple_code',\n",
    "\n",
    "            # sympy.plotting\n",
    "            'plot', 'textplot', 'plot_backends', 'plot_implicit', 'plot_parametric',\n",
    "\n",
    "            # sympy.interactive\n",
    "            'init_session', 'init_printing', 'interactive_traversal',\n",
    "\n",
    "            # sympy.testing\n",
    "            'test', 'doctest',\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "# fmt: off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69ce025",
   "metadata": {},
   "source": [
    "## **3.** Custom scraping code to download documentation for the 3 remaining libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbba2ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining = {\n",
    "    \"nltk\": {\n",
    "        \"url\": \"https://www.nltk.org/api/nltk.html\",\n",
    "        \"version\": \"3.8.1\",\n",
    "    },\n",
    "    \"tensorflow\": {\n",
    "        \"url\": \"https://www.tensorflow.org/api_docs/python/tf\",\n",
    "        \"version\": \"2.6.0\",\n",
    "    },\n",
    "    \"lxml\": {\n",
    "        \"urls\": [\n",
    "            \"https://lxml.de/apidoc/index.html\",\n",
    "            \"https://lxml.de/apidoc/lxml.html.html\",\n",
    "            \"https://lxml.de/apidoc/lxml.isoschematron.html\",\n",
    "        ],\n",
    "        \"version\": \"4.6.3\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b5de245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to access the html content of documentation pages\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "def get_html_soup(url: str) -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    Fetch the HTML content from the given URL and return a BeautifulSoup object.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise an error for bad responses\n",
    "    return BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2f2ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape the nltk documentation page\n",
    "nltk_soup = get_html_soup(remaining[\"nltk\"][\"url\"])\n",
    "nltk_members = {\"nltk\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feeff61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now have 1258 members for nltk.\n"
     ]
    }
   ],
   "source": [
    "# find the subpackages of nltk, and their members\n",
    "packages = nltk_soup.find(\"section\", id=\"subpackages\")\n",
    "for l1 in packages.select(\"li.toctree-l1\"):\n",
    "    _a = l1.select_one(\"a\")\n",
    "    module = _a.text.strip().split(\" \")[0]\n",
    "    if not module.startswith(\"nltk.\"):\n",
    "        continue\n",
    "\n",
    "    nltk_members.add(module)\n",
    "\n",
    "    for l3 in l1.select(\"li.toctree-l3\"):\n",
    "        _a = l3.select_one(\"a\")\n",
    "        submodule = _a.text.strip().strip(\"()\").split(\" \")[0]\n",
    "\n",
    "        if submodule.startswith(\"nltk.\"):\n",
    "            nltk_members.add(submodule)\n",
    "\n",
    "            for l4 in l3.select(\"li.toctree-l4\"):\n",
    "                _a = l4.select_one(\"a\")\n",
    "                member = f\"{submodule}.{_a.text.strip().rstrip('()').split(' ')[0]}\"\n",
    "                nltk_members.add(member)\n",
    "\n",
    "        else:\n",
    "            nltk_members.add(f\"{module}.{submodule}\")\n",
    "\n",
    "print(f\"Now have {len(nltk_members)} members for nltk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02089a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now have 1501 members for nltk.\n"
     ]
    }
   ],
   "source": [
    "# find the submodules of nltk, and their members\n",
    "packages = nltk_soup.find(\"section\", id=\"submodules\")\n",
    "for l1 in packages.select(\"li.toctree-l1\"):\n",
    "    _a = l1.select_one(\"a\")\n",
    "    module = _a.text.strip().split(\" \")[0]\n",
    "    if not module.startswith(\"nltk.\"):\n",
    "        continue\n",
    "\n",
    "    nltk_members.add(module)\n",
    "\n",
    "    for l2 in l1.select(\"li.toctree-l2\"):\n",
    "        _a = l2.select_one(\"a\")\n",
    "        member = f\"{module}.{_a.text.strip().rstrip('()').split(' ')[0]}\"\n",
    "        nltk_members.add(member)\n",
    "\n",
    "print(f\"Now have {len(nltk_members)} members for nltk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ee39b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk seems to allow all members to be imported from the top level\n",
    "top_level_members = {f\"nltk.{m.split('.')[-1]}\" for m in nltk_members if \".\" in m}\n",
    "nltk_members.update(top_level_members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57def91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 2783 members for nltk:\n",
      "\t['nltk', 'nltk.ALL', 'nltk.ARFF_Formatter', 'nltk.ARLSTem', 'nltk.ARLSTem2']\n"
     ]
    }
   ],
   "source": [
    "# format the nltk members\n",
    "nltk_members = sorted(nltk_members)\n",
    "remaining[\"nltk\"][\"modules\"] = sorted(set(m.split(\".\")[0] for m in nltk_members))\n",
    "remaining[\"nltk\"][\"members\"] = nltk_members\n",
    "print(f\"Have {len(nltk_members)} members for nltk:\\n\\t{nltk_members[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "719a2b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 217 modules to scrape for tensorflow.\n"
     ]
    }
   ],
   "source": [
    "# find all modules and submodules, and the urls to their 'overview' pages\n",
    "\n",
    "tf_members = set()\n",
    "tf_module_urls = {}\n",
    "\n",
    "tf_soup = get_html_soup(remaining[\"tensorflow\"][\"url\"])\n",
    "\n",
    "# extract links from expandable navigation bar\n",
    "for div in tf_soup.select(\"li.devsite-nav-expandable\"):\n",
    "    # get top level module name from the toggle title span\n",
    "    reference = div.select_one(\"span.devsite-nav-text\")\n",
    "    if not reference or not reference.text.startswith(\"tf\"):\n",
    "        continue\n",
    "\n",
    "    # clean up the module name\n",
    "    _title_text = reference.text.strip().replace(\"\\u200b\", \"\").replace(\" \", \"\")\n",
    "    tf_module = _title_text.replace(\"tf\", \"tensorflow\")\n",
    "    tf_members.add(tf_module)\n",
    "\n",
    "    # find the module overview link\n",
    "    for _a in div.select(\"li.devsite-nav-item a.devsite-nav-title\"):\n",
    "        member_text = _a.select_one(\"span.devsite-nav-text\").get_text().strip()\n",
    "        if member_text.lower() == \"overview\":\n",
    "            tf_module_urls[tf_module] = _a[\"href\"]\n",
    "            break\n",
    "\n",
    "    # find all submodules\n",
    "    for _a in div.select(\n",
    "        \"li.devsite-nav-item li.devsite-nav-expandable:not(li.devsite-nav-deprecated)\"\n",
    "    ):\n",
    "        # get top level module name from the toggle title span\n",
    "        reference = _a.select_one(\"span.devsite-nav-text\")\n",
    "        if not reference:\n",
    "            continue\n",
    "\n",
    "        # clean up the module name\n",
    "        _title_text = reference.text.strip().replace(\"\\u200b\", \"\").replace(\" \", \"\")\n",
    "        tf_submodule = f\"{tf_module}.{_title_text}\"\n",
    "        tf_members.add(tf_submodule)\n",
    "\n",
    "        # find the submodule overview link\n",
    "        for b in _a.select(\"li.devsite-nav-item a.devsite-nav-title\"):\n",
    "            member_text = b.select_one(\"span.devsite-nav-text\").get_text().strip()\n",
    "            if member_text.lower() == \"overview\":\n",
    "                tf_module_urls[tf_submodule] = b[\"href\"]\n",
    "                continue\n",
    "\n",
    "print(f\"Have {len(tf_module_urls)} modules to scrape for tensorflow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "550283a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/217 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [04:22<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 4716 members for tensorflow:\n",
      "\t['tensorflow.keras.reuters', 'tensorflow.lite.OpsSet', 'tensorflow.compat.raw_ops.MultiDeviceIteratorFromStringHandle', 'tensorflow.nn.approx_min_k', 'tensorflow.compat.raw_ops.GroupByWindowDataset', 'tensorflow.compat.raw_ops.SlidingWindowDataset', 'tensorflow.keras.losses.serialize', 'tensorflow.keras.numpy.all', 'tensorflow.compat.distributions.Laplace', 'tensorflow.compat.raw_ops.XlaSparseDenseMatmulGradWithAdamAndCsrInput']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# scrape docs for each tensorflow module\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "BASE_URL = \"https://www.tensorflow.org\"\n",
    "\n",
    "for tf_submodule, url in tqdm(list(tf_module_urls.items())):\n",
    "    # fetch the overview page for the module\n",
    "    _tf_sub_soup = get_html_soup(url=f\"{BASE_URL}{url}\")\n",
    "    body = _tf_sub_soup.select_one(\"div.devsite-article-body\")\n",
    "\n",
    "    # extract all member names from the body\n",
    "    for p in body.find_all(\"p\"):\n",
    "        _a = p.find(\"a\")\n",
    "        if not _a:\n",
    "            continue\n",
    "\n",
    "        member_text = _a.get_text().strip().rstrip(\"(...)\").split(\" \")[-1]\n",
    "        if not member_text or member_text.startswith(\"tf.\"):\n",
    "            continue\n",
    "\n",
    "        tf_members.add(f\"{tf_submodule}.{member_text}\")\n",
    "\n",
    "print(f\"Have {len(tf_members)} members for tensorflow:\\n\\t{list(tf_members)[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da7dbe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the tensorflow members\n",
    "tf_members = sorted(tf_members)\n",
    "remaining[\"tensorflow\"][\"modules\"] = sorted(set(m.split(\".\")[0] for m in tf_members))\n",
    "remaining[\"tensorflow\"][\"members\"] = tf_members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29e1abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method to scrape lxml documentation page\n",
    "def get_lxml_members(url: str, package: str, top_level: int) -> set:\n",
    "    _lxml_soup = get_html_soup(url=url)\n",
    "    _lxml_members = set()\n",
    "\n",
    "    # extract all top level modules\n",
    "    for top in _lxml_soup.select(f\"li.toctree-l{top_level}\"):\n",
    "        reference = top.select_one(\"a.reference\")\n",
    "        module = reference.text.strip() if reference else \"\"\n",
    "        module = module.split(\" \")[0]\n",
    "        if (\n",
    "            not module\n",
    "            or not module.startswith(f\"{package}.\")\n",
    "            or module.startswith(f\"{package}._\")\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        _lxml_members.add(module)\n",
    "\n",
    "        # extract all members of the top level modules\n",
    "        for a in top.select(f\"li.toctree-l{top_level + 1} > a\"):\n",
    "            name = a.text.strip()\n",
    "            # Some names include trailing ' — description'; strip that\n",
    "            if name.startswith(\"_\") or name.lower() in [\n",
    "                \"submodules\",\n",
    "                \"module contents\",\n",
    "            ]:\n",
    "                continue\n",
    "\n",
    "            name = name.split(\"—\", 1)[0].strip().rstrip(\"()\")\n",
    "            _lxml_members.add(f\"{module}.{name}\")\n",
    "\n",
    "    # extract all members of the module itself\n",
    "    for dt in _lxml_soup.select(\"dt.sig.sig-object.py\"):\n",
    "        if (_id := dt.get(\"id\")) and dt.select_one(\"span.descclassname\"):\n",
    "            if _id.startswith(f\"{package}.\") and not _id.startswith(f\"{package}._\"):\n",
    "                _lxml_members.add(_id)\n",
    "\n",
    "    return _lxml_members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db9cb31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 391 members for lxml:\n",
      "\t['lxml', 'lxml.ElementInclude', 'lxml.ElementInclude.FatalIncludeError', 'lxml.ElementInclude.LimitedRecursiveIncludeError', 'lxml.ElementInclude.default_loader', 'lxml.ElementInclude.include', 'lxml.builder', 'lxml.builder.ElementMaker', 'lxml.cssselect', 'lxml.doctestcompare']\n"
     ]
    }
   ],
   "source": [
    "# some manually scraped members\n",
    "lxml_members = {\"lxml\", \"lxml.get_include\"}\n",
    "\n",
    "lxml_members.update(\n",
    "    get_lxml_members(\n",
    "        url=remaining[\"lxml\"][\"urls\"][0],\n",
    "        package=\"lxml\",\n",
    "        top_level=3,\n",
    "    )\n",
    ")\n",
    "lxml_members.update(\n",
    "    get_lxml_members(\n",
    "        url=remaining[\"lxml\"][\"urls\"][1],\n",
    "        package=\"lxml.html\",\n",
    "        top_level=1,\n",
    "    )\n",
    ")\n",
    "lxml_members.update(\n",
    "    get_lxml_members(\n",
    "        url=remaining[\"lxml\"][\"urls\"][2],\n",
    "        package=\"lxml.isoschematron\",\n",
    "        top_level=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "lxml_members = sorted(lxml_members)\n",
    "remaining[\"lxml\"][\"modules\"] = sorted(set(m.split(\".\")[0] for m in lxml_members))\n",
    "remaining[\"lxml\"][\"members\"] = lxml_members\n",
    "print(f\"Have {len(lxml_members)} members for lxml:\\n\\t{lxml_members[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edb2710",
   "metadata": {},
   "source": [
    "## **4.** Save all of the documentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2070eb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have data for all 30 libraries:\n",
      "\t['bs4', 'chardet', 'cryptography', 'dateutil', 'django', 'folium', 'librosa', 'lxml', 'matplotlib', 'nltk', 'numpy', 'openpyxl', 'pandas', 'psutil', 'pytesseract', 'pytz', 'regex', 'requests', 'scipy', 'seaborn', 'sklearn', 'statsmodels', 'sympy', 'tensorflow', 'textblob', 'texttable', 'wordcloud', 'wordninja', 'xlwt', 'xmltodict']\n"
     ]
    }
   ],
   "source": [
    "from llm_cgr import save_json\n",
    "from datetime import datetime\n",
    "\n",
    "final_data = {\n",
    "    **manually_scraped,\n",
    "    **sphinx_scraped,\n",
    "    **remaining,\n",
    "}\n",
    "\n",
    "for library in DOCUMENTED_LIBRARIES:\n",
    "    assert library in final_data, f\"Missing documentation for {library}!\"\n",
    "\n",
    "print(\n",
    "    f\"Have data for all {len(DOCUMENTED_LIBRARIES)} libraries:\\n\\t{DOCUMENTED_LIBRARIES}\"\n",
    ")\n",
    "save_json(\n",
    "    data={\n",
    "        \"datetime\": datetime.now().isoformat(),\n",
    "        \"data\": final_data,\n",
    "    },\n",
    "    file_path=\"../data/libraries/documentation.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f3b373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
