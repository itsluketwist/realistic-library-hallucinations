{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcd368f9",
   "metadata": {},
   "source": [
    "# Merge results files from different runs\n",
    "\n",
    "Sometimes runs were cut short, or new models needed to be added.\n",
    "\n",
    "This notebook gives utility functions to merge those results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d113958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the project root\n",
    "PROJECT_ROOT = \"..\"\n",
    "\n",
    "# files to merge, with paths relative to the project root\n",
    "MAIN_FILE_PATH = (\n",
    "    \"output/new_models/spec_lib_typo_medium_2025-08-13T09:38:58.081298.json\"\n",
    ")\n",
    "MERGE_FILE_PATH = (\n",
    "    \"output/new_models/spec_lib_typo_medium_2025-08-13T20:39:52.610737.json\"\n",
    ")\n",
    "\n",
    "# merge type, either \"tasks\" or \"models\"\n",
    "MERGE_TYPE = \"tasks\"  # or \"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa7f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the utility function to merge results files!\n",
    "\n",
    "from typing import Literal, get_args\n",
    "from src import evaluate_hallucinations\n",
    "from llm_cgr import load_json, save_json\n",
    "from src.constants import HallucinationLevel\n",
    "from src.libraries.load import DEFAULT_DOCUMENTATION_FILE, DEFAULT_PYPI_PACKAGES_FILE\n",
    "\n",
    "MergeTypes = Literal[\n",
    "    \"tasks\",\n",
    "    \"models\",\n",
    "]\n",
    "\n",
    "\n",
    "def merge_results(\n",
    "    main_file: str,\n",
    "    merge_file: str,\n",
    "    merge_type: MergeTypes,\n",
    "    root: str = PROJECT_ROOT,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Merges two result files, in one of the following ways depending on the `merge_type`:\n",
    "        - \"tasks\": when a run was cut short, and we want to add more tasks.\n",
    "        - \"models\": when we want to expand the results with more models.\n",
    "    \"\"\"\n",
    "    # open both files\n",
    "    main_data = load_json(f\"{root}/{main_file}\")\n",
    "    merge_data = load_json(f\"{root}/{merge_file}\")\n",
    "\n",
    "    # assert runs are compatible\n",
    "    for key in [\n",
    "        \"run_id\",\n",
    "        \"hallucination_level\",\n",
    "        \"dataset_file\",\n",
    "        \"configured_temperature\",\n",
    "        \"configured_top_p\",\n",
    "        \"configured_max_tokens\",\n",
    "        \"system_prompt\",\n",
    "        \"mitigation_strategy\",\n",
    "    ]:\n",
    "        if main_data[\"metadata\"][key] != merge_data[\"metadata\"][key]:\n",
    "            raise ValueError(f\"Cannot merge results with different {key}.\")\n",
    "\n",
    "    # merge the data\n",
    "    if merge_type == \"tasks\":\n",
    "        main_data[\"generations\"].update(merge_data[\"generations\"])\n",
    "        main_data[\"errors\"].update(merge_data[\"errors\"])\n",
    "\n",
    "    elif merge_type == \"models\":\n",
    "        # can only merge results if all generations keys are the same\n",
    "        if set(main_data[\"generations\"].keys()) != set(\n",
    "            merge_data[\"generations\"].keys()\n",
    "        ):\n",
    "            raise ValueError(\"Cannot merge results with different generation keys.\")\n",
    "\n",
    "        # update the model responses for each key\n",
    "        for key in main_data[\"generations\"].keys():\n",
    "            main_data[\"generations\"][key][\"responses\"].update(\n",
    "                merge_data[\"generations\"][key][\"responses\"]\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Unknown merge type: {merge_type}. Use one of {get_args(MergeTypes)}.\"\n",
    "        )\n",
    "\n",
    "    # merge the metadata\n",
    "    main_data[\"metadata\"][\"end_datetime\"] = merge_data[\"metadata\"][\"end_datetime\"]\n",
    "\n",
    "    # save the merged data\n",
    "    save_json(\n",
    "        data=main_data,\n",
    "        file_path=f\"{root}/{main_file}\",\n",
    "    )\n",
    "\n",
    "    # determine the ground truth file based on the hallucination level\n",
    "    level = HallucinationLevel(main_data[\"metadata\"][\"hallucination_level\"])\n",
    "    ground_truth_file = (\n",
    "        DEFAULT_PYPI_PACKAGES_FILE\n",
    "        if level == HallucinationLevel.LIBRARY\n",
    "        else DEFAULT_DOCUMENTATION_FILE\n",
    "    )\n",
    "\n",
    "    # evaluate the merged hallucinations\n",
    "    evaluate_hallucinations(\n",
    "        results_file=f\"{root}/{main_file}\",\n",
    "        ground_truth_file=f\"{root}/{ground_truth_file}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaa8d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the merge\n",
    "\n",
    "merge_results(\n",
    "    main_file=MAIN_FILE_PATH,\n",
    "    merge_file=MERGE_FILE_PATH,\n",
    "    merge_type=MERGE_TYPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2127f6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266ee2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7237536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7031f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eddcf76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
