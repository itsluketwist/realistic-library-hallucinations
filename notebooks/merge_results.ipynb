{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcd368f9",
   "metadata": {},
   "source": [
    "# Merge results files from different runs\n",
    "\n",
    "Sometimes runs were cut short, or new models needed to be added.\n",
    "\n",
    "This notebook gives utility functions to merge those results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d113958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the project root\n",
    "PROJECT_ROOT = \"..\"\n",
    "\n",
    "# files to merge, with paths relative to the project root\n",
    "MAIN_FILE_PATH = (\n",
    "    \"output/specify/member/spec_mem_typo_small_2025-08-05T17:56:01.467103.json\"\n",
    ")\n",
    "MERGE_FILE_PATH = \"output/specify/spec_mem_typo_small_2025-08-16T10:38:22.965028.json\"\n",
    "\n",
    "# merge type, either \"tasks\" or \"models\"\n",
    "MERGE_TYPE = \"models\"\n",
    "\n",
    "# which models to merge, None to merge all models\n",
    "MODELS = [\"gpt-4o-mini-2024-07-18\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aa7f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the utility function to merge results files!\n",
    "\n",
    "from typing import Literal, get_args\n",
    "from src import evaluate_hallucinations\n",
    "from llm_cgr import load_json, save_json\n",
    "from src.constants import HallucinationLevel\n",
    "from src.libraries.load import DEFAULT_DOCUMENTATION_FILE, DEFAULT_PYPI_PACKAGES_FILE\n",
    "\n",
    "MergeTypes = Literal[\n",
    "    \"tasks\",\n",
    "    \"models\",\n",
    "]\n",
    "\n",
    "\n",
    "def merge_results(\n",
    "    main_file: str,\n",
    "    merge_file: str,\n",
    "    merge_type: MergeTypes,\n",
    "    root: str = PROJECT_ROOT,\n",
    "    models: list[str] | None = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Merges two result files, in one of the following ways depending on the `merge_type`:\n",
    "        - \"tasks\": when a run was cut short, and we want to add more tasks.\n",
    "        - \"models\": when we want to expand the results with more models.\n",
    "    \"\"\"\n",
    "    # open both files\n",
    "    main_data = load_json(f\"{root}/{main_file}\")\n",
    "    merge_data = load_json(f\"{root}/{merge_file}\")\n",
    "\n",
    "    # assert runs are compatible\n",
    "    for key in [\n",
    "        \"run_id\",\n",
    "        \"hallucination_level\",\n",
    "        # \"dataset_file\",\n",
    "        \"configured_temperature\",\n",
    "        \"configured_top_p\",\n",
    "        \"configured_max_tokens\",\n",
    "        \"system_prompt\",\n",
    "        \"mitigation_strategy\",\n",
    "    ]:\n",
    "        if main_data[\"metadata\"][key] != merge_data[\"metadata\"][key]:\n",
    "            raise ValueError(f\"Cannot merge results with different {key}.\")\n",
    "\n",
    "    # merge the data\n",
    "    if merge_type == \"tasks\":\n",
    "        main_data[\"generations\"].update(merge_data[\"generations\"])\n",
    "        main_data[\"errors\"].update(merge_data[\"errors\"])\n",
    "\n",
    "    elif merge_type == \"models\":\n",
    "        # can only merge results if all merge keys are a subset of the main keys\n",
    "        if not set(merge_data[\"generations\"].keys()).issubset(\n",
    "            set(main_data[\"generations\"].keys())\n",
    "        ):\n",
    "            raise ValueError(\"Cannot merge results with different generation keys.\")\n",
    "\n",
    "        # update the model responses for each key\n",
    "        for key in main_data[\"generations\"].keys():\n",
    "            # skip keys not in the merge data\n",
    "            if key not in merge_data[\"generations\"]:\n",
    "                continue\n",
    "\n",
    "            if models is None:\n",
    "                # update with everything\n",
    "                main_data[\"generations\"][key][\"responses\"].update(\n",
    "                    merge_data[\"generations\"][key][\"responses\"]\n",
    "                )\n",
    "                if _errors := merge_data[\"errors\"].get(key, None):\n",
    "                    if key not in main_data[\"errors\"]:\n",
    "                        main_data[\"errors\"][key] = _errors\n",
    "                    else:\n",
    "                        main_data[\"errors\"][key].extend(_errors)\n",
    "\n",
    "            else:\n",
    "                # only update with specific model data\n",
    "                for model in models:\n",
    "                    main_data[\"generations\"][key][\"responses\"][model] = merge_data[\n",
    "                        \"generations\"\n",
    "                    ][key][\"responses\"].get(model, [])\n",
    "                    if _errors := [\n",
    "                        e\n",
    "                        for e in merge_data[\"errors\"].get(key, [])\n",
    "                        if e[\"model\"] == model\n",
    "                    ]:\n",
    "                        if key not in main_data[\"errors\"]:\n",
    "                            main_data[\"errors\"][key] = _errors\n",
    "                        else:\n",
    "                            main_data[\"errors\"][key].extend(_errors)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Unknown merge type: {merge_type}. Use one of {get_args(MergeTypes)}.\"\n",
    "        )\n",
    "\n",
    "    # merge the metadata\n",
    "    main_data[\"metadata\"][\"end_datetime\"] = merge_data[\"metadata\"][\"end_datetime\"]\n",
    "\n",
    "    # save the merged data\n",
    "    save_json(\n",
    "        data=main_data,\n",
    "        file_path=f\"{root}/{main_file}\",\n",
    "    )\n",
    "\n",
    "    # determine the ground truth file based on the hallucination level\n",
    "    level = HallucinationLevel(main_data[\"metadata\"][\"hallucination_level\"])\n",
    "    ground_truth_file = (\n",
    "        DEFAULT_PYPI_PACKAGES_FILE\n",
    "        if level == HallucinationLevel.LIBRARY\n",
    "        else DEFAULT_DOCUMENTATION_FILE\n",
    "    )\n",
    "\n",
    "    # evaluate the merged hallucinations\n",
    "    evaluate_hallucinations(\n",
    "        results_file=f\"{root}/{main_file}\",\n",
    "        ground_truth_file=f\"{root}/{ground_truth_file}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dbaa8d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the merge\n",
    "\n",
    "merge_results(\n",
    "    main_file=\"output/mitigate/self_analysis/spec_lib_fabrication_2025-08-31T04:06:57.357245.json\",\n",
    "    merge_file=\"output/mitigate/spec_lib_fabrication_2025-09-03T21:31:09.200438.json\",\n",
    "    merge_type=\"models\",\n",
    "    models=[\"deepseek-chat\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7237536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
